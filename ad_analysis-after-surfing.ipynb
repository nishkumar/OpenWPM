{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import PIL.Image as Image\n",
    "import urllib2\n",
    "from urlparse import urlparse\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# html_files = []\n",
    "# for file in os.listdir(os.getcwd()+'/sources'):\n",
    "#     html_files.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from fake_useragent import UserAgent\n",
    "ua = UserAgent()\n",
    "\n",
    "urls = [\"https://www.google.com/search?q=women%27s+winter+boots\",\n",
    "    \"https://www.amazon.com/s/ref=nb_sb_noss_1?url=search-alias%3Daps&field-keywords=womens+winter+boots\",\n",
    "    \"https://www.zappos.com/womens-winter-boots\",\n",
    "    \"https://www.amazon.com/Timberland-Womens-Kenniston-Winter-Medium/dp/B01MT7WTDX/\",\n",
    "    \"https://www.ebay.com/itm/Timberland-Womens-14-Inch-Premium-Side-Zip-Lace-Waterproof-Black-Boots-8632A/162719687948\",'http://www.yahoo.com']\n",
    "headers = {'User-Agent': ua.firefox}\n",
    "for url in urls:\n",
    "    response = requests.get(url, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = 'https://www.rediff.com/'\n",
    "# print url\n",
    "# urlContent = urllib2.urlopen(url).read()\n",
    "\n",
    "# soup = BeautifulSoup(''.join(urlContent))\n",
    "soup = BeautifulSoup(response.content)\n",
    "\n",
    "# HTML = open('sources/' + html_files[3]).read()\n",
    "# soup= BeautifulSoup(HTML, 'html.parser')\n",
    "# print html_files[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgTagList =  soup.find_all('img')\n",
    "aList = soup.find_all('a')\n",
    "scriptTags = soup.find_all('script')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgTagSrc = []\n",
    "aHref = []\n",
    "scriptLink = []\n",
    "for imgItem, aItem, item in zip(imgTagList,aList, scriptTags):\n",
    "    try:\n",
    "        imgTagSrc.append(imgItem['src'])\n",
    "    except:\n",
    "        continue\n",
    "    try:\n",
    "        aHref.append(aItem['href'])\n",
    "    except:\n",
    "        continue\n",
    "    try:\n",
    "        scriptLink.append(item['src'])\n",
    "    except:\n",
    "        continue    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original URL: consent.cmp.oath.com Redirect URL: consent.cmp.oath.com\n",
      "Original URL: consent.cmp.oath.com Redirect URL: consent.cmp.oath.com\n",
      "Original URL: mbp.yimg.com Redirect URL: mbp.yimg.com\n",
      "Original URL: mbp.yimg.com Redirect URL: mbp.yimg.com\n",
      "Original URL: s.yimg.com Redirect URL: s.yimg.com\n",
      "Original URL: mbp.yimg.com Redirect URL: mbp.yimg.com\n",
      "Original URL: mbp.yimg.com Redirect URL: mbp.yimg.com\n",
      "Original URL: mbp.yimg.com Redirect URL: mbp.yimg.com\n",
      "Original URL: mbp.yimg.com Redirect URL: mbp.yimg.com\n",
      "Original URL: mbp.yimg.com Redirect URL: mbp.yimg.com\n",
      "Original URL: mbp.yimg.com Redirect URL: mbp.yimg.com\n",
      "Original URL: mbp.yimg.com Redirect URL: mbp.yimg.com\n",
      "Original URL: mbp.yimg.com Redirect URL: mbp.yimg.com\n",
      "Original URL: mbp.yimg.com Redirect URL: mbp.yimg.com\n",
      "Original URL: mbp.yimg.com Redirect URL: mbp.yimg.com\n",
      "Original URL: mbp.yimg.com Redirect URL: mbp.yimg.com\n",
      "Original URL: mbp.yimg.com Redirect URL: mbp.yimg.com\n"
     ]
    }
   ],
   "source": [
    "for link in scriptLink:\n",
    "    try:\n",
    "        new_url = requests.get(link).url\n",
    "        old_domain = urlparse(link).hostname\n",
    "        new_domain = urlparse(new_url).hostname\n",
    "    #     if old_domain!=new_domain:\n",
    "        print \"Original URL:\", urlparse(link).hostname, \"Redirect URL:\",urlparse(new_url).hostname\n",
    "    except:\n",
    "        print \"Invalid URL: \",link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = []\n",
    "for item in aList:\n",
    "    try:\n",
    "        links.append(item['href'])\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=0\n",
    "for item in aList:\n",
    "    attr = item.attrs\n",
    "    if \"target\" in attr and attr[\"target\"]==\"_blank\":\n",
    "        url = attr[\"href\"]\n",
    "        if len(url)>500:\n",
    "            print len(url)\n",
    "            new_url = requests.get(url).url\n",
    "            old_domain = urlparse(url).hostname\n",
    "            new_domain = urlparse(new_url).hostname\n",
    "            if old_domain!=new_domain:\n",
    "                print \"Original URL:\", urlparse(url).hostname, \"Redirect URL:\",urlparse(new_url).hostname\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib2\n",
    "from os.path import basename\n",
    "from urlparse import urlsplit\n",
    "from bs4 import BeautifulSoup # for HTML parsing\n",
    "\n",
    "global urlList\n",
    "urlList = []\n",
    "fileName = './downloadImages'\n",
    "# recursively download images starting from the root URL\n",
    "def downloadImages(url, level): # the root URL is level 0\n",
    "    print url\n",
    "    global urlList\n",
    "    if url in urlList: # prevent using the same URL again\n",
    "        return\n",
    "    urlList.append(url)\n",
    "    try:\n",
    "        urlContent = urllib2.urlopen(url).read()\n",
    "    except:\n",
    "        return\n",
    "\n",
    "    soup = BeautifulSoup(''.join(urlContent))\n",
    "    # find and download all images\n",
    "    imgTags = soup.findAll('img')\n",
    "    for imgTag in imgTags:\n",
    "        imgUrl = imgTag['src']\n",
    "        try:\n",
    "            imgData = urllib2.urlopen(imgUrl).read()\n",
    "            fileName = basename(urlsplit(imgUrl)[2])\n",
    "            output = open(fileName,'wb')\n",
    "            output.write(imgData)\n",
    "            output.close()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # if there are links on the webpage then recursively repeat\n",
    "    if level > 0:\n",
    "        linkTags = soup.findAll('a')\n",
    "        if len(linkTags) > 0:\n",
    "            for linkTag in linkTags:\n",
    "                try:\n",
    "                    linkUrl = linkTag['href']\n",
    "                    downloadImages(linkUrl, level - 1)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "# main\n",
    "downloadImages('http://www.yahoo.com', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fake_useragent import UserAgent\n",
    "ua = UserAgent()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ua.chrome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
